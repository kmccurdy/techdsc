DiEM25

Technological Sovereignty: democratising technology and innovation 

1st Green Paper

Authors: 

## Introduction: Technological Sovereignty – We decide over our technologies 

In Europe and across the globe technological systems and the ways in which they are shaped and governed are powerful ways to shape society. Technology has become a central form of social power and we have to democratise this power if we want to have collective and democratic control over the shape of our future. Technological changes have been accelerating and the private sector has an increasing influence over the directions of these changes. However, it is becoming ever more obvious that the concentration of capital-driven technological change is detrimental to the flourishing of people and a healthy democracy. 

Digitalisation, energy and mobility systems, housing, the future of work, of our health, of freedom, of equality, of our public sphere, of cities, of the environment and of states and democracy – the shape and quality of all of this is entwined with technological changes. Combining the democratisation of societies with the democratisation of technologies is therefore not only about the need to regulate particular technologies to prevent harm. Democratising technology is about finding ways of democratically shaping and governing technologies for the common good, to bring technological power under democratic control and to use technological advances to benefit the many and to help societies and people flourish in the 21st century.

To democratise our societies we must also democratise our technologies. But democratising technologies can only be successful within an agenda to democratise societies. This is why DiEM25 includes policies for technological sovereignty within its progressive agenda for Europe. Europe can become a beacon of hope if it unites political, social and technological progress. Especially digital technologies, however, can also help us to create systems and new institutions that update democracy to the needs and opportunities of the 21st century. Technologies have to be an integral part of democracies of the future – as objects of democratic control and as tools to enhance our democratic powers. 

Technological development, however, is not a goal in itself – don’t let the merchants of Silicon Valley’s ideas tell you otherwise. Technology has to serve human progress. DiEM25 firmly supports human rights in the face of technology – the flourishing of humans, all humans, comes first, and technology second. Conceived in this way, technological development can be a formidable force for good. Technology is a key contributor to our civilization’s ability to provide health, welfare, social interaction, freedom, safety and happiness. DiEM25 firmly supports sound, positive and democratic technological development that benefits mankind, and rejects Luddite anti-technological thinking. 

However, this does not mean that all technological development is good. And negative costs and consequences of technologies must be taken into account – it must no longer be the case that profits from new technologies are privatised and the risks are socialised. In the face of accelerating technological change we need to safeguard and extend our individual and collective self-determination. We must not accept the control that designers and owners of technological systems or even technological systems themselves have and might have over our lives. Instead, we must invent and shape the democratic processes and institutions that help us to democratise technology and innovation. 

To aspire to technological sovereignty is to gain individual and collective self-determination concerning the choices and effects that technologies create in our lives and societies. Technological sovereignty is about finding ways to put people through democratic processes in charge of technologies. Of course, technological sovereignty starts with individual people and their self-determination. But it doesn’t end there. We have to invent ways in which organisations, municipalities, businesses, regional, national and European democratic institutions can be empowered to make self-determined choices and gain democratic control over technologies. We need democratic control over the input we provide, which is used for technological ends – which aspects of our lives, which ideas, which needs and which aspirations influence technological ends? We need democratic control over the ways in which we are subjected to technology as workers, as citizens, as people in need, as politicians: How can we make sure that equality and freedom are protected and our lives can be lived just in the face of growing technological influence over us? We need democratic control over the research and knowledge that powers technology – How can we find ways to collectively own and govern our collectively produced knowledge to support democratic forms of innovation that really address the pressing problems of our times?  

### The undemocratic state of current technological change in Europe [This needs to be tailored to the problems described in the respective chapters]

- The concentration of technological power, often in corporations, that translates into economic, political and cultural influence and directs the benefits of new technologies towards the few, the shareholders and capital owners. This is tightly entangled with financialised capitalism where investors shape technological change purely on a for maximum profit basis. 
- The privatisation of knowledge and data, which monopolises collectively created ideas, capabilities, information and resources. This feeds a regime of surveillance capitalism where data is "valuable" for creating tools to manipulate consumers. Furthermore, intellectual property monopolies hinder innovation and are a crucial mechanism how big corporations secure their powerful positions. 
- The extreme centralisation and concentration of influence over the World Wide Web, one of the most significant infrastructures of our society, through corporations and states. Already this creates highly undemocratic development and use of artificial intelligence systems that make decisions over people’s lives in opaque and unaccountable ways.
- The technocratic decision making in research and politics where experts make decisions about shaping the future through research and innovation in intransparent and unaccountable ways, with narrow views about what research and innovation should be good for. This leads to a narrow focus on "high-tech" technological innovation and economic growth that leaves out of sight social and cultural innovations and innovations that may not lead to maximum profit but to social well-being and significant ecological sustainability. Relatedly, there is a lack of diversity of people who do research, development and decision making in technology.

We propose policies that help to democratically shape the technologies that are such an important part of our lives, economies and societies. We propose to make use of the power of the public sector and of civil society to seed innovations and unleash their potential for social good.

[Summary of most important policies]

# 1. Re:inventing a free, secure and decentralized internet

## European Data/Platform Autonomy

Those who are old enough to have experienced the INTERNET in the late 1990ies will remember how radical it felt to have a decentralized (rhizomatic) network of interconnected computers unaffected by the hegemonic discourse of traditional media outlets and arbitrary governmental control. This INTERNET and its accompanying promise of a new, progressive age of unlimited and uncontrolled communication is long gone. Instead the INTERNET has become a medieval marketplace where everyone is keen to sacrifice safety, responsibility and sustainability for a quick dime.  

We think that the progressive version of the INTERNET doesn't need to remain a nostalgic memory. In the last 20 years technologies and concepts have been developed that'll allow to facilitate a democratic, decentralized, less-commercialized, secure, anonymous and encrypted INTERNET. An INTERNET led and inspired by 21st century social and ethical standards.


In the conceivable future the INTERNET as we know it will spread even further into the private and public life of every human being. A development that is commonly referred to as Internet of Things. Its underlying protocol IPv6 is able to provide 340 sextillion IP-adresses. That is an unimaginable amount of quadrillions of microcomputers, each of which could be connected to all the others via the INTERNET. Yet another reason why we consider a structural change of the INTERNET to be of utmost importance.

We propose an evolutionary boost for the INTERNET which we want to achieve by sophisticated regulations and law amendments as well as publicly funded and facilitated structures that will allow european citizens to switch sides. And that will be there as a safety net when the old INTERNET has been altered unusable or unaffordable.   

The structures proposed on the following pages will also implement a reasonable business model to attract private investors without sacrificing the safety and data autonomy of the user/citizens.

### 1.1 Proposal: European Autonomous Data Network [P6](https://github.com/kmccurdy/techdsc/wiki/P6-European-Autonomous-Data-Network)

The basic structure for our next level INTERNET will be the European Autonomous Data Network (EADN). By proposing this we identify the centralized structure of the INTERNET as a main issue for its current deformation. Contemporary cloud computer services are oligopolistic, unsecure and privately controlled structural nodes that are harvesting our data. At the same time this centralized server structure provides a ready-made framework for government surveillance.

TL;DR: We are not safe on company servers.

As a solution we propose a decentralized, anonymous, autonomous, encrypted peer-to-peer-network. Think of a gigantic network of personal computers, tablets and smartphones helping to organize, structure and maintain a serverless and decentralized network. This network creates itself automatically with the initial help of bootstrap servers provided by the European Union. The data is stored on hardware and uses bandwith provided by users of the network. All data on this network is fragmented (split up into pieces of e.g. 1 MByte) and encrypted to ensure its safety and integrity. Popular Data is being spreaded increasingly to the physical location where it is required. No client has a complete overview over the network and thus the bigger the network becomes, the more secure it will get. To incentivize users to provided hardware and bandwidth there will be the option to implement a micropayment system (e.g. using a blockchain secured virtual currency).

To establish this European Autonomous Data Network we propose a European Save Networking Fund set up by the EU that funds research on an open-source and easy-to-use solution implementing the specifications mentioned above.

Furthermore we propose that the EU provides bootstrap servers and a minimum amount of storage capacity (storing encrypted data chunks) to get the network up and running.

To ensure the competitiveness of such a system further legislation might be necessary, both to ensure proof of competence as well as to prevent big players of distorting the decentralized structure of  the network.

### 1.2. Proposal: Platform independent and safe Social Media Infrastructure and Online Publishing [P1](https://github.com/kmccurdy/techdsc/wiki/P1-Suggestion-for-a-European-Progressive-Media-Fund)

We believe that internet users have the right to express their opinion and to reach people who like their opinion and to get updates on their favourite celebrities sexlife without being subject to surveillance and targeted advertising. Also we believe that internet users have the right to build a sustainable network of online contacts without having to trust an internet oligopolist on safeguarding their data. We need a system where it is safe for us to share whatever we want with our family and friends without the risk to share it with third parties. 

At present the opposite is the case: Information about personal characteristics and behaviors is linked, combined and utilized across companies, databases, platforms, devices, and services in real-time. Individuals are constantly surveyed and evaluated, categorized and grouped, rated and ranked, numbered and quantified, included or excluded,  and, as a result, treated differently. [P8](https://github.com/kmccurdy/techdsc/wiki/P8-Tech-Pillar-Suggestions-DSC-Lower-Austria)

While there are alternatives in place for nearly every service provided by an internet oligopolist (e.g. Mastodon, Diaspora etc.) it is next to impossible to gather a critical mass of users on any of those alternatives - and thus makes them insufficient as an alternative.

We think that as long as data vending and targeted advertising is the main kind of revenue in the online realm any effective solution will aways end up as a corrupted one. To prevent that and create the framework for the development of alternative social media and online content distribution systems we rely on two main principles:

- strong and effective legislation
- public funding for decentralised, encrypted and standardised solutions

To protect our data and to keep the internet a fun and safe place.

One of the technologies we consider as promising to reach the objective mentioned above is an online publish/subscribe tool (e.g. an API) that operates from the user's own computer or smartphone and is not depending on servers, is not exposing interests to other people than to the intended ones and is protecting the flow of information in transit. It would be mandatory for services like e.g. twitter and facebook to supply interfaces e.g. a uniform simple document upload format, so that user could safely access their user base without having to reveal more information than necessary. Nevertheless the final objective is a truly distributed and private social network.

##(waiting on comments by Claudio about the extent of this proposal, An existing document or container standard that supports your idea and  a legal policy that would make it mandatory for publishing platforms to accept a uniform simple document upload format)

To allow content producers to be rewarded for their work (be it art, text, image, video, music, podcast, live stream or whatever might come up in the future) we propose a mandatory anonymous micropayment system by which any content can be bought for a few cents. (See e.g. taler.net for an example) [P4](https://github.com/kmccurdy/techdsc/wiki/P4-Input-DSC-Vienna2) & Comments on that Proposal by Carlo von Lynx

Once those tools and accompanying legislation are implemented targeted advertising will become impossible and unnecessary while an effective and fair revenue system will replace it.

### 1.3. Short-term measures 
[P9](https://github.com/kmccurdy/techdsc/wiki/P9-Questionnaire-submitted-by-Diego-Naranjo-(DiEM25-Belgium,-NC-member-and-Anna-Mazgal)) (& Accompanying e-mail communication)

As long as the measures outlined above are being developed and deployed we propose short-term measures to limit the damage that the current structure of the internet performs. Some of these short term measures have already been part of the original draft of the e-Privacy Regulation. The e-Privacy Regulation is meant to be the main framework to protect online communication and is currently being "watered down" by the European Council.

#### 1.3.1. Privacy by design / Privacy by default
We are very concerned about  the de facto standard of insecure communications via unencrypted emails and messenger apps. Unauthorised access to a computer system is a crime under EU legislation (Directive 2013/40/EC). Following this logic we consider it unacceptable that unauthorised access to an individual’s computer system could be permitted by default.
We demand Privacy by design and Privacy by default as a mandatory standard for all hardware and software developed, sold and used in the EU.

Privacy by design means that all stages of the creation of the hardware and software incorporates a high level of protection of the users privacy. Privacy by default means that our devices and software are set to protect our data, with options to change this, if we wish.

Thereby we explicitly include the necessity to provide an incentive to develop technical solutions where citizens can provide location data to so called location-based-services without any privacy risks. Technical solutions based on local computation in the end-user’s device should always be preferred over centralised tracking.

#### 1.3.2. Reasonable Regulation of User Consent 
Regarding User Consent we advocate a regulation that ensures that Software, Apps and Smart Devices are seeking for consent as user-friendly as possible and only for permissions that are crucial to perform their main task(s). Instead of being asked for general consent upon installation the user shall be asked to Opt-In for every task that the Software/App/Smart Device wishes to perform on their device. „All-or-Nothing“ consent - e.g. a mandatory general consent for the Software/App/Smart Device to function - is most likely NOT in accordance with the GDPR.

#### 1.3.3. Communication Data / Metadata Protection
Communication Data (email, voice mail, chat, videoconference, VoIP) is sensitive data and there shall be no „legitimate interest“ exception to use this data without explicit user consent (see above). Metadata processed for security and QoS purposes should be anonymised as soon as possible and the storage of metadata should be limited to what is strictly necessary for the designated purpose. 

#### 1.3.4. Tracking Regulation
To protect users against third party tracking, we demand that so-called cookie walls - notification windows that prevent access to a service if users do not agree to terms of service - should be prohibited. Also we embrace a prohibition of the common practice of excluding users that use ad-blocking or likewise protection software. We strongly demand this to be implemented asap to websites  that offer public services, services that are financed by public funds or medical services. 

#### 1.3.5. Providers Disclosure Regarding Law Enforcement
Providers of electronic communication services should be obliged to publish all requests received by law enforcement agencies or comparable state agencies. This publication should include the number of requests received from law enforcement agencies, the legal justification invoked and the provider’s response in a meaningful aggregated format. We consider this to be a matter of public interest and transparency towards public authorities.

# 2. Democratising algorithms and data

The 21st century has seen an accelerating expansion of information technology in more and more domains of everyday life, with citizens positioned both as *sources* of the data collected to accumulate privately-held wealth and enable state and commercial surveillance, and *targets* of the resulting applications, which can entail manipulation, exclusion, and other social harms. 

Unfortunately, this expansion of information technology has not been accompanied by expanded democratic control, resulting in a massive concentration of wealth, power, and surveillance capabilities in a few hands, and little accountability or oversight by the public. This is the state of affairs today that Diem25 seeks to change.

## 2.1 We need democratic control over data collection

Data collection has always carried a dual risk: *inclusion* in certain datasets can render citizens in general, and members of marginalized groups in particular, vulnerable to being *targeted* for certain harms - but *exclusion* from datasets can lead to other harms in turn. As a non-technical example, consider the decision to identify oneself as a member of an ethnic minority on a government census. Not identifying one's ethnicity can lead to the risk of *exclusion*: perhaps if members of one's ethnic group in the relevant district are undercounted, crucial social services, such as linguistic and cultural support, will not be provided at sufficient levels to meet the community's needs. On the other hand, including data on one's ethnic identity brings with it the risk of being *targeted* by the state or an affiliated malicious actor, on which point history provides many tragic accounts of the possible consequences.

How does information technology change data collection today? Mostly by making it easier than ever to collect, store, and process data at unprecedented variety and scale, thus amplifying this dual risk in both directions. To illustrate this variety, here's a partial list of the different kinds of data whose collection is facilitated by digital technology:

- personal data, e.g. what you might enter into a form (name, age, sex, race, home address, nationality, ...)
- biometric data, e.g. what you might use to unlock an iPhone (face, fingerprint, ...)
- personally authored content, e.g. what you might post on Facebook or send to a friend (text, audio, video, ...)
- behavioral data, e.g. how you interact with a device or website (GPS location, sites visited, time spent on news feeds, clicks on ads, grip on steering wheel, ...)
- behavioral biometric data, e.g. device interactions that identify you personally (speed of typing, direction of mouse movements, ...)
- second-order inferred data, namely predicting a data attribute you did not provide (e.g. age or race) based on other data about you (e.g. name or location)

As digital data collection extends to more and more arenas of life - our online communication and media consumption, "smart" devices in our homes and workplaces, CCTV cameras on our streets, automotive computer systems in our cars, and on and on - it becomes increasingly important that we, as citizens, know *who* collects *what* data about us for *which* purpose, and retain the choice to withold our data at will; this transparency is needed to achieve meaningful accountability for information technology, and build public trust that our data will not be used to exploit us. In cases where this trust cannot be established, we must regulate data collection, and, if necessary, ban it altogether.

### 2.1.1 Reining in the data brokers: short-term measures

In the near future, the most urgent priority regarding data must be to curtail its undisclosed circulation to unidentified third parties, with special attention to sensitive personal data collected for public-interest purposes. The GDPR offers an excellent starting point, and has already demonstrated that bold legislation can put the tech giants on notice - but we must go further!

- **End involuntary data trading**:  For all domains in which data are collected, restrict the sale or access of individual data to third parties unless the individual providing the data expressly consents to grant that specifically named third party access, separately from granting general platform access (i.e. checking one box to 'agree to terms and conditions' will not cover third-party sharing), and separately for each named third party. ([P8](https://github.com/kmccurdy/techdsc/wiki/P8-Tech-Pillar-Suggestions-DSC-Lower-Austria), L26-27; [P9](https://github.com/kmccurdy/techdsc/wiki/P9-Questionnaire-submitted-by-Diego-Naranjo-(DiEM25-Belgium,-NC-member-and-Anna-Mazgal)), L24) <!-- no proposal with this specific wording, but the source is the current European Spring program draft, p15, point 1.3 -->
- **Restrict state-enabled corporate surveillance of the public**: From Lockheed Martin running data collection for the 2001 and 2011 UK censuses to American police departments using Amazon's facial recognition software for real-time database matching, "public-private partnerships" which purport to increase "efficiency" in fact represent taxpayer money spent to funnel ever more data on nonconsenting citizens to unaccountable corporations. These practices must be banned. In cases where assistance is required for core state data processing capacities, such as the census, only partnerships with nonprofit organizations should be considered.


### 2.1.2 Our data belongs to us: rethinking ownership in data collection

In the longer term, our vision must shift from reactive to constructive: how can we build the social infrastructure and tools to make data collection inclusive, and harness the liberatory power of technology for the public good? 

- **Fund development on open, secure protocols for data ownership**: The original foundation of the open web was open protocols, enabling the routing of communication within and across networks - but platform monopolies have been able to build a proprietary data layer on top of these protocols, leading to surveillance and lock-in for users. We must actively fund development on protocols for secure routing and communication which empowers us to truly own our data, and be able to move it between platforms at will.  <!-- n.b. this proposal is based on a discussion with Ele of OSCoin - and I may be misremembering it, so I hope others with more expertise help whip this in shape! - also, this is very related to the overall European Data Network proposal, but aims to be a bit more generic --> ([P1](https://github.com/kmccurdy/techdsc/wiki/P1-Suggestion-for-a-European-Progressive-Media-Fund); [P6](https://github.com/kmccurdy/techdsc/wiki/P6-European-Autonomous-Data-Network); [P16](https://github.com/kmccurdy/techdsc/wiki/P16-Public-Digital-Identity); [P4](https://github.com/kmccurdy/techdsc/wiki/P4-Input-DSC-Vienna2), L26; [P13](https://github.com/kmccurdy/techdsc/wiki/P13-Addition-to-proposal-Autonomous-Data-Network); [P17](https://github.com/kmccurdy/techdsc/wiki/P17-Proposal-Input-from-Carlo))
- **Establish a public data commons**: Building and maintaining quality data resources, and ensuring their availability for applications in the public interest (e.g. scientific research, good governance analysis, etc.), provides a counterweight to the vast data stores of platform monopolies. Subject to appropriate protections, data produced by public institutions should be be made open and accessible by default; individual citizens should be able to contribute their data to the commons on a voluntary basis. 
Public institutions engaged in the *collection* of data for the commons must also conduct a thorough stakeholder analysis, with the aim of inclusive data collection along the dimensions of gender, race, class, nationality, sexual orientation, inter alia. Institutions should assess the risks for marginalized populations associated with representation in the dataset (inclusionary harm - risk of being targeted) versus absence from the dataset (exclusionary harm). 
([P9](https://github.com/kmccurdy/techdsc/wiki/P9-Questionnaire-submitted-by-Diego-Naranjo-(DiEM25-Belgium,-NC-member-and-Anna-Mazgal)), L28, L122) <!-- n.b. also overlap with transparency pillar section 2.5 on open data for transparency in governance; c.f. also Renata's W20 brief, proposal 1, recommendation 4 -->
- **Redistribute the value our data creates**: Platform monopolies have built empires of wealth on our data, but we haven't been invited to share in the proceeds. This obviously must change, although **how** that happens is a topic for debate - so please, Diemers, **give your feedback**! Some thoughts:
	- "Data as labor": [P12](https://github.com/kmccurdy/techdsc/wiki/P12-Work-force-and-data) suggests the model of treating data producers as workers, and ensuring compensation for the value generated by their data. This proposal resonates in certain aspects with other critiques of the online data economy; see also, for example, Jaron Lanier's "Who Owns the Future?", and the [Wages for Facebook](http://wagesforfacebook.com/) campaign. [P18](https://github.com/kmccurdy/techdsc/wiki/P18-Intellectual-Property-for-Contributors) also raises the possibility of improved recognition of economic value for content providers, under a broader conception of 'content'.
	- However, there are some strong counterpoints: [P17](https://github.com/kmccurdy/techdsc/wiki/P17-Proposal-Input-from-Carlo) suggests simply banning proprietary data collection altogether, while [P9](https://github.com/kmccurdy/techdsc/wiki/P9-Questionnaire-submitted-by-Diego-Naranjo-(DiEM25-Belgium,-NC-member-and-Anna-Mazgal)) L28 cautions against "models based on "data ownership" that envision the possibility to to trade personal data for services and benefits. It would affect the vulnerable populations that have less resources and digital literacy and therefore enable forced trade of fundamental rights." - on which point a personal note of agreement from me: as most data collection for advertising and so on is focused on predicting consumption, it's fairly well established in the current data economy that *data from wealthier people is more valuable*, raising the risk that compensation for data could inadvertently end up reinforcing current hierarchies and power structures.


## 2.2 We need democratic control over data-driven applications

Independently of data collection, there is also a pressing need for greater oversight in the *application* of data-driven information technology; for example, your picture may not appear in the image database used to train a facial recognition system, but if that system is used on you, its biases and potential harms are of direct concern to you. Nevertheless, while the scope of a data-driven application may differ drastically from the context of the original data collection, in practice the two processes are often closely intertwined - especially in the case of algorithmic technology, where application generally involves continuously collecting new data to evaluate and refine system performance. In any event, information technology applications based on data inherit the dual risks described above, and often constitute the point at which these harms are realized.

Algorithmic profiling based on given or inferred data attributes can lead to an individual being *targeted* for those attributes - indeed, that is often the point. One possible harm resulting from targeting is *discrimination*; for example, a [2015 study](http://www1.icsi.berkeley.edu/~mct/pubs/pets15.pdf) found that Google systematically delivered ads for lower-paying jobs to profiles identified as women job-seekers. Another possible harm receiving increased attention lately is the possibility an individual might be targeted for purposes of *manipulation* by third parties, ranging from unscrupulous advertisers (for instance, [online casinos targeting gambling addicts](https://www.theguardian.com/society/2017/aug/31/gambling-industry-third-party-companies-online-casinos)) to [political propagandists](https://www.theguardian.com/news/series/cambridge-analytica-files) and promulgators of "fake news."
On the other side of this dual risk, algorithmic systems trained on a dataset which *excludes*, or underrepresents, a particular population - usually a historically marginalized group - offer another form of discriminatory harm: reduced system accuracy on that population, or reduced system capacity to serve that population. Examples of this include Siri [directing women](https://www.salon.com/2016/01/29/siri_find_me_an_abortion_provider_apples_weird_anti_choice_glitch_is_finally_on_its_way_out/) with reproductive health inquiries to misleadingly-labeled religious anti-abortion centers, and law enforcement using facial recognition systems which are [known to have a higher error rate for women and people of color](https://www.theverge.com/2018/5/23/17384632/amazon-rekognition-facial-recognition-racial-bias-audit-data).

Data-driven applications are used to inform incredibly consequential outcomes for citizen's lives, from media consumption to job opportunities to [eligibility for welfare benefits](https://algorithmwatch.org/en/high-risk-citizens/). To ensure they do not reinforce inequality and manipulation, but serve the public interest, we need transparency and democratic governance over their use.

### 2.2.1 Algorithmic accountability: Defining our rights

[P20](https://github.com/kmccurdy/techdsc/wiki/P20-Proposal:-Algorithmic-Accountability) With regard to the use of algorithms in everyday life, we demand that the following rights be recognized:

* **Right of interaction**: Citizens have the right to know when they are or aren't interacting with an algorithm.
  * When an individual receives an outcome from a service that is based wholly or partially on algorithmic computation, this should be clearly and transparently communicated.
  * AI is not allowed to "conceal" itself in interactions with unknowing citizens, as seen in the initial [Google Duplex tests](https://www.theverge.com/2018/6/27/17508728/google-duplex-assistant-reservations-demo).
  * On the other side, businesses are not allowed to "conceal" human data processing to [users who believe themselves to be interacting with an algorithm](https://www.theguardian.com/technology/2018/jul/06/artificial-intelligence-ai-humans-bots-tech-companies).

* **Right of equal treatment**: Citizens have the right to be free from algorithmic discrimination.
  * If algorithmic services provide outputs of consistently lower value or quality to or about users coming from historically marginalized backgrounds, this constitutes discrimination ([example from google search](http://time.com/5209144/google-search-engine-algorithm-bias-racism/)).
  * Users should be able to compare outputs based on different demographic profiles (e.g. "would this search result be the same if I were to change the gender or age the algorithm has inferred for me?").

### 2.2.2 Algorithmic emancipation: Building an intelligent, accountable future

- **Public audits** ([P20](https://github.com/kmccurdy/techdsc/wiki/P20-Proposal:-Algorithmic-Accountability)): The EU shall develop an independent public institution to conduct algorithmic audits in a transparent manner, with resources allocated proportional to estimated scope of a) affected citizens and b) potential harms. 
- **Opt-out** ([P20](https://github.com/kmccurdy/techdsc/wiki/P20-Proposal:-Algorithmic-Accountability)): An "algorithmic opt-out" rule shall be established: for any algorithmic service, a user can choose to receive an outcome with a "default" profile (i.e. with the user's personal/demographic attributes removed from calculation). 
- **Labor intelligence** ([P15](https://github.com/kmccurdy/techdsc/wiki/P15-Labor-Intelligence---Shared-Worker-Governance---Cooperative-Intelligence)): The EU shall fund a research institute working specifically at the intersection of Artificial Intelligence and labor with the follow mandate: 
	- It shall explore and prototype intelligent systems with various axes of worker control (i.e. ranging  from 'being designed along worker-friendly principles' to 'responsive to real-time  worker input' to 'explicity includes coorperative decision mechanism for key decisions').
	- It shall partner with existing organizations, in particular **cooperatives** (platform and otherwise), to  apply and test systems under real-world conditions.
	- It shall assess outcomes with particular attention to humanistic goals, quality of life, and worker-centered perspectives, emphasizing the dignity and autonomy of workers.
	- It shall require particular attention to barriers faced by marginalized workers and workers from traditionally excluded backgrounds.

# 3. Free Knowledge for democratic innovation [Joren]

- intellectual property 
- open source 
- open access 

- topics on education (e.g. proposal #5)
- diversity and inclusion in the tech sector (c.f. upcoming work from Renata)

# 4. Collaboration and democratic decisions on technology  [Christoph]

Every technological development is the result of choices. Choices made by governments, researchers, investors, consumers, manufacturers, distributors, users and many others. No technology is god-given or given by the "invisible hand of the market". No technology is unavoidable or unopposable. And no technology is neutral. Technology is always value-laden. The way we fund, adopt, use and regulate technology, or not, reflects society’s choice of its values and priorities. That is a reflection of our society’s priorities and values. However, in the way how this currently works, the priorities and values that influence decisions in research and innovation reflect the worldviews and interests of technocratic researchers, policy-makers and above all venture capitalists that want to take research “to the market”, i.e. want to maximise their profits. 

We need to democratise research and the decision-making that selects priorities and strategies for research and innovation. This entails democratising funding decisions for research and innovation that are taken in politics, science and industry. Democratising decision-making in technology is necessarily an effort to democratise the science system and to democratise the economy. 

DiEM25 believes that, as a society, we have the duty to be aware of the fact that we make choices on technology. We must be more aware of how choices around technology are rooted in values, and openly discuss and decide on them in a democratic way. The agenda setting of the debate around technology and values should be open, inclusive and democratic and not set by research and the technology industry itself. To every technological option there are always alternatives – including non-technological forms of change and problem solving. The necessary democratic instruments and institutions, capable to address the complexities of the democratisation of 21st century technologies, must be found. 

## 4.1. Democratising technocratic decision-making in research and innovation

DiEM25 proposes to make use of mission-oriented public funding to address the crises of the European economy. As part of its European Green New Deal DiEM25 proposes Funding Green Investment‐led Recovery and setting up a new agency for managing and funding Europe’s Green Transition and Green Energy Union. More such instruments need to be devised that make use of the risk-taking, mission-oriented funding powers of public institutions. But we need to democratise these institutions as well.  	

For research and innovation the European Union is already a major funder and decision-making body that shapes the research and innovations that affect our lives. In the ongoing program “Horizon 2020” the EU has been spending 80 billion € to fund research and innovation in the years 2014 to 2020. The following program “Horizon Europe” entails 100 billion € for research and innovation funding in the years 2021 to 2027. These are vast sums of money. While the programs are proposed by the European Commission and debated in the European Council and the European Parliament, the individual funding decisions are taken in a technocratic manner by Brussels bureaucrats, lobbyists and scientific experts. We have to put European citizens in charge of this whole process through democratic control of this funding. Citizens need to have a strong say in the research and technologies that influence their futures. And research and innovation need to become accountable to citizens and their needs and expectations.

### 4.1.1. Proposal: Participatory budgeting for research and innovation funding through a digital platform 

This is a 21st century institution that democratises the funding of research and innovation and gives citizens a stronger say in defining problems that should be addressed through research and innovation with the help of a digital platform and the idea of digital direct democracy. This is participatory budgeting on a transnational level, democratising significant drivers of societal change: research and innovation.

Democratise funding: citizens crowd funding 

The platform needs to contain a crowd funding system that allows European citizens to allocate public money, e.g. from the EU’s “Horizon Europe”, through their decisions on the platform. Every EU citizen that uses the platform has the right to allocate the same amount of public money to research or innovation projects. It is imperative that research and innovation are not only focused on “high-tech” on this platform but that different forms of research and innovation, including technological, social and cultural innovation, are addressed. The projects apply with their proposals and a sum of money that would allow them to start the work. As in crowdfunding if enough citizens give money to a proposed project it is successful and gets money from the fund. The potential strength of crowd funding over voting is that it allows for greater diversity in the successful projects, i.e. even if only 10 % of the citizens support a project it can still be successful if it raises enough money through these 10 % of citizens. Through voting only projects that get the support of a majority would be successful. Crowdfunding better addresses the need for diversity in research and innovation.

A powerful amount of money from public funds for research and innovation needs to be put into this platform to give citizens an actual say in shaping the trajectories of research and innovation. One third of the overall EU budget for research and innovation or of new public funding instruments, i.e. around 30 billion €, seems reasonable. The other two thirds could be allocated as usual through the science system or through existing EU institutions. 

Democratise agenda setting: citizens’ needs crowdsourcing 

The platform should also entail the function for citizens to name and describe problems and needs that they think should be solved through research and innovation. While the problems are openly sourced there would also be a form of voting on the platform to rank these. The top ranking problems are then turned into pillars for the funding side of the platform such that researchers and innovators can apply with their proposals for these. Localised forms of problem sourcing and money allocation could be introduced in the platform as well, such that participatory agenda setting and budgeting on a national, regional or municipal level could take place. 

Ensure Participation 

It seems unlikely that an equally distributed group of Europeans participate in this platform if it is simply open to all citizens. As in most forms of citizen participation well-educated and higher-earning people would probably dominate the platform. Therefore particular procedures need to be devised that ensure that a representative group of European citizens is active on the platform and shapes the decisions. This could be done through drawing several thousand citizens from Europe by lot – and by paying them a sum of money as compensation for participating. Furthermore, the platform needs to have its content in all languages of the European Union.

## 4.2. Foster a collaborative and democratic economy

The problem of decision-making in research and innovation extends beyond funding agencies and scientists. Most of the decisions on innovations are taken within the economic sphere by capitalists. To democratise research and innovation we also need to find ways to democratise the economy and to foster more decentralised economic arrangements, collective decision-making and structures for shared responsibilities. In short, we need to find ways to democratise economic decision making. With the help of digital systems new ways of organising businesses, innovation processes and collaboration and collective ownership become possible. We need to tap into these and help more a more democratic economy and more democratic technologies to emerge. 

Every technology is the result of collaboration. Collaboration between developers, public institutions, users, researchers, citizens, businesses and more. Innovative societies foster collaborations. And they have public institutions and investments that foster the exchange of ideas and provide resources for the new to emerge - technologies depend on the public. For too long have regulations from the time of the first industrial revolution and power structures aided in monopolising and privatising technology. Artificial boundaries that block or slow down the creative sharing of technology damage society. The more value and technology are shared; the more they can create value in return. 

By sharing technology and knowledge, society ensures that much more value is created than by “protecting” it. DiEM25 firmly supports sharing technology and knowledge, and rejects monopolies or rent seeking. With the growing importance of technological systems in the creation of value we need to devise ways to share the benefits of technology to all of society and to use it as a way to improve the lives of the many and not further boost the wealth of the few.

Digital technologies can help to create new and more democratic organisational forms and shape processes that coordinate economic activities and value beyond the reductionist market logics that have colonised our societies. 
…
… 
